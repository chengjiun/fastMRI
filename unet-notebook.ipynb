{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T09:23:28.427848Z",
     "start_time": "2019-09-08T09:23:28.422731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chengjiun/Workspace/fastMRI\n"
     ]
    }
   ],
   "source": [
    "%cd ~/Workspace/fastMRI/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T09:23:30.732568Z",
     "start_time": "2019-09-08T09:23:30.123143Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import pathlib\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from common.args import Args\n",
    "from common.subsample import MaskFunc\n",
    "from data import transforms\n",
    "from data.mri_data import SliceData\n",
    "from models.unet.unet_model import UnetModel\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class DataTransform:\n",
    "    \"\"\"\n",
    "    Data Transformer for training U-Net models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mask_func, resolution, which_challenge, use_seed=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mask_func (common.subsample.MaskFunc): A function that can create a mask of\n",
    "                appropriate shape.\n",
    "            resolution (int): Resolution of the image.\n",
    "            which_challenge (str): Either \"singlecoil\" or \"multicoil\" denoting the dataset.\n",
    "            use_seed (bool): If true, this class computes a pseudo random number generator seed\n",
    "                from the filename. This ensures that the same mask is used for all the slices of\n",
    "                a given volume every time.\n",
    "        \"\"\"\n",
    "        if which_challenge not in ('singlecoil', 'multicoil'):\n",
    "            raise ValueError(f'Challenge should either be \"singlecoil\" or \"multicoil\"')\n",
    "        self.mask_func = mask_func\n",
    "        self.resolution = resolution\n",
    "        self.which_challenge = which_challenge\n",
    "        self.use_seed = use_seed\n",
    "\n",
    "    def __call__(self, kspace, target, attrs, fname, slice):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            kspace (numpy.array): Input k-space of shape (num_coils, rows, cols, 2) for multi-coil\n",
    "                data or (rows, cols, 2) for single coil data.\n",
    "            target (numpy.array): Target image\n",
    "            attrs (dict): Acquisition related information stored in the HDF5 object.\n",
    "            fname (str): File name\n",
    "            slice (int): Serial number of the slice.\n",
    "        Returns:\n",
    "            (tuple): tuple containing:\n",
    "                image (torch.Tensor): Zero-filled input image.\n",
    "                target (torch.Tensor): Target image converted to a torch Tensor.\n",
    "                mean (float): Mean value used for normalization.\n",
    "                std (float): Standard deviation value used for normalization.\n",
    "                norm (float): L2 norm of the entire volume.\n",
    "        \"\"\"\n",
    "        kspace = transforms.to_tensor(kspace)\n",
    "        # Apply mask\n",
    "        seed = None if not self.use_seed else tuple(map(ord, fname))\n",
    "        masked_kspace, mask = transforms.apply_mask(kspace, self.mask_func, seed)\n",
    "        # Inverse Fourier Transform to get zero filled solution\n",
    "        image = transforms.ifft2(masked_kspace)\n",
    "        # Crop input image\n",
    "        image = transforms.complex_center_crop(image, (self.resolution, self.resolution))\n",
    "        # Absolute value\n",
    "        image = transforms.complex_abs(image)\n",
    "        # Apply Root-Sum-of-Squares if multicoil data\n",
    "        if self.which_challenge == 'multicoil':\n",
    "            image = transforms.root_sum_of_squares(image)\n",
    "        # Normalize input\n",
    "        image, mean, std = transforms.normalize_instance(image, eps=1e-11)\n",
    "        image = image.clamp(-6, 6)\n",
    "\n",
    "        target = transforms.to_tensor(target)\n",
    "        # Normalize target\n",
    "        target = transforms.normalize(target, mean, std, eps=1e-11)\n",
    "        target = target.clamp(-6, 6)\n",
    "        return image, target, mean, std, attrs['norm'].astype(np.float32)\n",
    "\n",
    "\n",
    "def create_datasets(args):\n",
    "    train_mask = MaskFunc(args.center_fractions, args.accelerations)\n",
    "    dev_mask = MaskFunc(args.center_fractions, args.accelerations)\n",
    "\n",
    "    train_data = SliceData(\n",
    "        root=args.data_path / f'{args.challenge}_train',\n",
    "        transform=DataTransform(train_mask, args.resolution, args.challenge),\n",
    "        sample_rate=args.sample_rate,\n",
    "        challenge=args.challenge\n",
    "    )\n",
    "    dev_data = SliceData(\n",
    "        root=args.data_path / f'{args.challenge}_val',\n",
    "        transform=DataTransform(dev_mask, args.resolution, args.challenge, use_seed=True),\n",
    "        sample_rate=args.sample_rate,\n",
    "        challenge=args.challenge,\n",
    "    )\n",
    "    return dev_data, train_data\n",
    "\n",
    "\n",
    "def create_data_loaders(args):\n",
    "    dev_data, train_data = create_datasets(args)\n",
    "    display_data = [dev_data[i] for i in range(0, len(dev_data), len(dev_data) // 16)]\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    dev_loader = DataLoader(\n",
    "        dataset=dev_data,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    display_loader = DataLoader(\n",
    "        dataset=display_data,\n",
    "        batch_size=16,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader, dev_loader, display_loader\n",
    "\n",
    "\n",
    "def train_epoch(args, epoch, model, data_loader, optimizer, writer):\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "    start_epoch = start_iter = time.perf_counter()\n",
    "    global_step = epoch * len(data_loader)\n",
    "    for iter, data in enumerate(data_loader):\n",
    "        input, target, mean, std, norm = data\n",
    "        input = input.unsqueeze(1).to(args.device)\n",
    "        target = target.to(args.device)\n",
    "\n",
    "        output = model(input).squeeze(1)\n",
    "        loss = F.l1_loss(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss = 0.99 * avg_loss + 0.01 * loss.item() if iter > 0 else loss.item()\n",
    "        writer.add_scalar('TrainLoss', loss.item(), global_step + iter)\n",
    "\n",
    "        if iter % args.report_interval == 0:\n",
    "            logging.info(\n",
    "                f'Epoch = [{epoch:3d}/{args.num_epochs:3d}] '\n",
    "                f'Iter = [{iter:4d}/{len(data_loader):4d}] '\n",
    "                f'Loss = {loss.item():.4g} Avg Loss = {avg_loss:.4g} '\n",
    "                f'Time = {time.perf_counter() - start_iter:.4f}s',\n",
    "            )\n",
    "        start_iter = time.perf_counter()\n",
    "    return avg_loss, time.perf_counter() - start_epoch\n",
    "\n",
    "\n",
    "def evaluate(args, epoch, model, data_loader, writer):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    start = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        for iter, data in enumerate(data_loader):\n",
    "            input, target, mean, std, norm = data\n",
    "            input = input.unsqueeze(1).to(args.device)\n",
    "            target = target.to(args.device)\n",
    "            output = model(input).squeeze(1)\n",
    "\n",
    "            mean = mean.unsqueeze(1).unsqueeze(2).to(args.device)\n",
    "            std = std.unsqueeze(1).unsqueeze(2).to(args.device)\n",
    "            target = target * std + mean\n",
    "            output = output * std + mean\n",
    "\n",
    "            norm = norm.unsqueeze(1).unsqueeze(2).to(args.device)\n",
    "            loss = F.mse_loss(output / norm, target / norm, size_average=False)\n",
    "            losses.append(loss.item())\n",
    "        writer.add_scalar('Dev_Loss', np.mean(losses), epoch)\n",
    "    return np.mean(losses), time.perf_counter() - start\n",
    "\n",
    "\n",
    "def visualize(args, epoch, model, data_loader, writer):\n",
    "    def save_image(image, tag):\n",
    "        image -= image.min()\n",
    "        image /= image.max()\n",
    "        grid = torchvision.utils.make_grid(image, nrow=4, pad_value=1)\n",
    "        writer.add_image(tag, grid, epoch)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for iter, data in enumerate(data_loader):\n",
    "            input, target, mean, std, norm = data\n",
    "            input = input.unsqueeze(1).to(args.device)\n",
    "            target = target.unsqueeze(1).to(args.device)\n",
    "            output = model(input)\n",
    "            save_image(target, 'Target')\n",
    "            save_image(output, 'Reconstruction')\n",
    "            save_image(torch.abs(target - output), 'Error')\n",
    "            break\n",
    "\n",
    "\n",
    "def save_model(args, exp_dir, epoch, model, optimizer, best_dev_loss, is_new_best):\n",
    "    torch.save(\n",
    "        {\n",
    "            'epoch': epoch,\n",
    "            'args': args,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'best_dev_loss': best_dev_loss,\n",
    "            'exp_dir': exp_dir\n",
    "        },\n",
    "        f=exp_dir / 'model.pt'\n",
    "    )\n",
    "    if is_new_best:\n",
    "        shutil.copyfile(exp_dir / 'model.pt', exp_dir / 'best_model.pt')\n",
    "\n",
    "\n",
    "def build_model(args):\n",
    "    model = UnetModel(\n",
    "        in_chans=1,\n",
    "        out_chans=1,\n",
    "        chans=args.num_chans,\n",
    "        num_pool_layers=args.num_pools,\n",
    "        drop_prob=args.drop_prob\n",
    "    ).to(args.device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model(checkpoint_file):\n",
    "    checkpoint = torch.load(checkpoint_file)\n",
    "    args = checkpoint['args']\n",
    "    model = build_model(args)\n",
    "    if args.data_parallel:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    optimizer = build_optim(args, model.parameters())\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return checkpoint, model, optimizer\n",
    "\n",
    "\n",
    "def build_optim(args, params):\n",
    "    optimizer = torch.optim.RMSprop(params, args.lr, weight_decay=args.weight_decay)\n",
    "    return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T09:23:35.937044Z",
     "start_time": "2019-09-08T09:23:35.928504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1.post2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T09:24:41.625652Z",
     "start_time": "2019-09-08T09:24:41.619258Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T10:10:50.735876Z",
     "start_time": "2019-09-08T10:10:50.729532Z"
    }
   },
   "outputs": [],
   "source": [
    "class args():\n",
    "    num_pools = 4 # , help='Number of U-Net pooling layers')\n",
    "    drop_prob = 0.0 # , help='Dropout probability')\n",
    "    num_chans = 32 # , help='Number of U-Net channels')\n",
    "    batch_size = 16 # , type=int, help='Mini batch size')\n",
    "    num_epochs = 15 # , help='Number of training epochs')\n",
    "    lr = 0.001# , help='Learning rate')\n",
    "    lr_step_size = 40 # , help='Period of learning rate decay')\n",
    "    lr_gamma = 0.1 # , help='Multiplicative factor of learning rate decay')\n",
    "    weight_decay = 0. # , help='Strength of weight decay regularization')\n",
    "    report_interval = 100 # , help='Period of loss reporting')\n",
    "    data_parallel = True # , help='If set, use multiple GPUs using data parallelism')\n",
    "    device = 'cuda' # , help='Which device to train on. Set to \"cuda\" to use the GPU')\n",
    "    exp_dir = pathlib.Path('input/checkpoints') # , help='Path where model and results should be saved')\n",
    "    resume = False # , help='If set, resume the training from a previous model checkpoint. ''\"--checkpoint\" should be set with this')\n",
    "    checkpoint = '' # , type=str, help='Path to an existing checkpoint. Used along with \"--resume\"')\n",
    "    \n",
    "    \n",
    "    seed = 42 #, type=int, help='Seed for random number generators')\n",
    "    resolution=320# , type=int, help='Resolution of images'\n",
    "    challenge='singlecoil' # , 'multicoil'], required=True, help='Which challenge')\n",
    "    data_path = pathlib.Path('./input') # , required=True, help='Path to the dataset')\n",
    "    sample_rate=1.# ,help='Fraction of total volumes to include')\n",
    "    accelerations = [4, 8] #[4, 8], type=int,\n",
    "    # help='Ratio of k-space columns to be sampled. If multiple values are '\n",
    "    # provided, then one of those is chosen uniformly at random for each volume.')\n",
    "    center_fractions = [0.08, 0.04] #, type=float,\n",
    "    # help='Fraction of low-frequency k-space columns to be sampled. Should '\n",
    "    #   'have the same length as accelerations')\n",
    "\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T10:10:37.992502Z",
     "start_time": "2019-09-08T10:10:16.787038Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:<class '__main__.args'>\n",
      "INFO:root:DataParallel(\n",
      "  (module): UnetModel(\n",
      "    (down_sample_layers): ModuleList(\n",
      "      (0): ConvBlock(in_chans=1, out_chans=32, drop_prob=0.0)\n",
      "      (1): ConvBlock(in_chans=32, out_chans=64, drop_prob=0.0)\n",
      "      (2): ConvBlock(in_chans=64, out_chans=128, drop_prob=0.0)\n",
      "      (3): ConvBlock(in_chans=128, out_chans=256, drop_prob=0.0)\n",
      "    )\n",
      "    (conv): ConvBlock(in_chans=256, out_chans=256, drop_prob=0.0)\n",
      "    (up_sample_layers): ModuleList(\n",
      "      (0): ConvBlock(in_chans=512, out_chans=128, drop_prob=0.0)\n",
      "      (1): ConvBlock(in_chans=256, out_chans=64, drop_prob=0.0)\n",
      "      (2): ConvBlock(in_chans=128, out_chans=32, drop_prob=0.0)\n",
      "      (3): ConvBlock(in_chans=64, out_chans=32, drop_prob=0.0)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "args.exp_dir.mkdir(parents=True, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=args.exp_dir / 'summary')\n",
    "\n",
    "if args.resume:\n",
    "    checkpoint, model, optimizer = load_model(args.checkpoint)\n",
    "    args = checkpoint['args']\n",
    "    best_dev_loss = checkpoint['best_dev_loss']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    del checkpoint\n",
    "else:\n",
    "    model = build_model(args)\n",
    "    if args.data_parallel:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    optimizer = build_optim(args, model.parameters())\n",
    "    best_dev_loss = 1e9\n",
    "    start_epoch = 0\n",
    "logging.info(args)\n",
    "logging.info(model)\n",
    "\n",
    "train_loader, dev_loader, display_loader = create_data_loaders(args)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, args.lr_step_size, args.lr_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T10:10:38.007696Z",
     "start_time": "2019-09-08T10:10:38.003672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T18:29:22.142643Z",
     "start_time": "2019-09-08T10:12:04.438702Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  0/ 15] Iter = [   0/2172] Loss = 1.12 Avg Loss = 1.12 Time = 8.2612s\n",
      "INFO:root:Epoch = [  0/ 15] Iter = [ 100/2172] Loss = 0.297 Avg Loss = 0.6849 Time = 0.2725s\n",
      "INFO:root:Epoch = [  0/ 15] Iter = [ 200/2172] Loss = 0.4155 Avg Loss = 0.4972 Time = 5.1924s\n",
      "INFO:root:Epoch = [  0/ 15] Iter = [ 300/2172] Loss = 0.4079 Avg Loss = 0.4277 Time = 0.2727s\n",
      "INFO:root:Epoch = [  0/ 15] Iter = [ 400/2172] Loss = 0.3599 Avg Loss = 0.3958 Time = 5.1033s\n",
      "INFO:root:Epoch = [  0/ 15] Iter = [ 500/2172] Loss = 0.2685 Avg Loss = 0.3834 Time = 0.2735s\n",
      "INFO:root:Epoch = [  0/ 15] Iter = [ 600/2172] Loss = 0.356 Avg Loss = 0.3719 Time = 5.0398s\n",
      "INFO:root:Epoch = [  0/ 15] Iter = [ 700/2172] Loss = 0.2949 Avg Loss = 0.3623 Time = 0.2772s\n",
      "INFO:root:Epoch = [  0/ 15] Iter = [ 800/2172] Loss = 0.436 Avg Loss = 0.3619 Time = 4.6569s\n",
      "INFO:root:Epoch = [  0/ 15] Iter = [ 900/2172] Loss = 0.3895 Avg Loss = 0.3592 Time = 0.2739s\n",
      "INFO:root:Epoch = [  0/ 15] Iter = [1000/2172] Loss = 0.3067 Avg Loss = 0.3626 Time = 4.4888s\n",
      "INFO:root:Epoch = [  0/ 15] Iter = [1100/2172] Loss = 0.3791 Avg Loss = 0.3646 Time = 0.2775s\n",
      "INFO:root:Epoch = [  0/ 15] Iter = [1200/2172] Loss = 0.3079 Avg Loss = 0.3593 Time = 4.6064s\n",
      "INFO:root:Epoch = [  0/ 15] Iter = [1300/2172] Loss = 0.3646 Avg Loss = 0.3528 Time = 0.2744s\n",
      "INFO:root:Epoch = [  0/ 15] Iter = [1400/2172] Loss = 0.4431 Avg Loss = 0.3551 Time = 3.7513s\n",
      "INFO:root:Epoch = [  0/ 15] Iter = [1500/2172] Loss = 0.4792 Avg Loss = 0.3436 Time = 0.2753s\n",
      "INFO:root:Epoch = [  0/ 15] Iter = [1600/2172] Loss = 0.399 Avg Loss = 0.3423 Time = 3.1823s\n",
      "INFO:root:Epoch = [  0/ 15] Iter = [1700/2172] Loss = 0.306 Avg Loss = 0.3483 Time = 0.2759s\n",
      "INFO:root:Epoch = [  0/ 15] Iter = [1800/2172] Loss = 0.2755 Avg Loss = 0.3485 Time = 0.7579s\n",
      "INFO:root:Epoch = [  0/ 15] Iter = [1900/2172] Loss = 0.338 Avg Loss = 0.3475 Time = 0.2746s\n",
      "INFO:root:Epoch = [  0/ 15] Iter = [2000/2172] Loss = 0.3805 Avg Loss = 0.3442 Time = 1.2705s\n",
      "INFO:root:Epoch = [  0/ 15] Iter = [2100/2172] Loss = 0.3257 Avg Loss = 0.335 Time = 0.2790s\n",
      "/home/chengjiun/Softwares/anaconda3/envs/py36_pytorch0.4/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "INFO:root:Epoch = [   0/  15] TrainLoss = 0.3429 DevLoss = 0.02331 TrainTime = 1848.4060s DevTime = 161.4501s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [   0/2172] Loss = 0.3109 Avg Loss = 0.3109 Time = 8.4176s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [ 100/2172] Loss = 0.2779 Avg Loss = 0.3183 Time = 0.2734s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [ 200/2172] Loss = 0.2932 Avg Loss = 0.3336 Time = 1.4388s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [ 300/2172] Loss = 0.282 Avg Loss = 0.3337 Time = 0.2738s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [ 400/2172] Loss = 0.3403 Avg Loss = 0.3355 Time = 0.2743s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [ 500/2172] Loss = 0.4626 Avg Loss = 0.3318 Time = 0.2779s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [ 600/2172] Loss = 0.3186 Avg Loss = 0.3449 Time = 0.2804s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [ 700/2172] Loss = 0.3333 Avg Loss = 0.3427 Time = 0.2727s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [ 800/2172] Loss = 0.3329 Avg Loss = 0.3367 Time = 0.2783s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [ 900/2172] Loss = 0.4462 Avg Loss = 0.3342 Time = 0.2773s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [1000/2172] Loss = 0.2398 Avg Loss = 0.3333 Time = 0.2749s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [1100/2172] Loss = 0.2691 Avg Loss = 0.3284 Time = 0.2755s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [1200/2172] Loss = 0.2808 Avg Loss = 0.3256 Time = 0.9836s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [1300/2172] Loss = 0.2537 Avg Loss = 0.334 Time = 0.2777s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [1400/2172] Loss = 0.3244 Avg Loss = 0.3294 Time = 0.2762s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [1500/2172] Loss = 0.5981 Avg Loss = 0.3363 Time = 0.2765s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [1600/2172] Loss = 0.2973 Avg Loss = 0.3238 Time = 0.2743s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [1700/2172] Loss = 0.3479 Avg Loss = 0.3294 Time = 0.2760s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [1800/2172] Loss = 0.3082 Avg Loss = 0.3238 Time = 0.2761s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [1900/2172] Loss = 0.2415 Avg Loss = 0.3262 Time = 0.2778s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [2000/2172] Loss = 0.3228 Avg Loss = 0.3246 Time = 0.2744s\n",
      "INFO:root:Epoch = [  1/ 15] Iter = [2100/2172] Loss = 0.2994 Avg Loss = 0.3335 Time = 0.2771s\n",
      "INFO:root:Epoch = [   1/  15] TrainLoss = 0.3312 DevLoss = 0.02141 TrainTime = 1827.4025s DevTime = 165.9430s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [   0/2172] Loss = 0.3115 Avg Loss = 0.3115 Time = 7.2030s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [ 100/2172] Loss = 0.2983 Avg Loss = 0.3217 Time = 1.9982s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [ 200/2172] Loss = 0.2462 Avg Loss = 0.3313 Time = 2.1474s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [ 300/2172] Loss = 0.3365 Avg Loss = 0.3378 Time = 0.2786s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [ 400/2172] Loss = 0.4057 Avg Loss = 0.3298 Time = 4.6938s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [ 500/2172] Loss = 0.3377 Avg Loss = 0.3245 Time = 0.2769s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [ 600/2172] Loss = 0.3286 Avg Loss = 0.3279 Time = 3.5801s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [ 700/2172] Loss = 0.3478 Avg Loss = 0.3333 Time = 0.2744s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [ 800/2172] Loss = 0.3154 Avg Loss = 0.3308 Time = 5.0739s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [ 900/2172] Loss = 0.251 Avg Loss = 0.3259 Time = 0.4910s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [1000/2172] Loss = 0.4097 Avg Loss = 0.3242 Time = 4.4438s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [1100/2172] Loss = 0.361 Avg Loss = 0.3341 Time = 0.3141s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [1200/2172] Loss = 0.2859 Avg Loss = 0.3219 Time = 2.8142s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [1300/2172] Loss = 0.3119 Avg Loss = 0.317 Time = 3.8000s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [1400/2172] Loss = 0.2709 Avg Loss = 0.3223 Time = 3.2771s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [1500/2172] Loss = 0.4645 Avg Loss = 0.3177 Time = 0.2760s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [1600/2172] Loss = 0.3307 Avg Loss = 0.3183 Time = 4.9505s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [1700/2172] Loss = 0.3774 Avg Loss = 0.3197 Time = 0.2780s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [1800/2172] Loss = 0.5536 Avg Loss = 0.3276 Time = 4.9612s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [1900/2172] Loss = 0.475 Avg Loss = 0.3349 Time = 1.7145s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [2000/2172] Loss = 0.3124 Avg Loss = 0.3195 Time = 3.9272s\n",
      "INFO:root:Epoch = [  2/ 15] Iter = [2100/2172] Loss = 0.2731 Avg Loss = 0.3147 Time = 1.4893s\n",
      "INFO:root:Epoch = [   2/  15] TrainLoss = 0.314 DevLoss = 0.02024 TrainTime = 1822.0829s DevTime = 160.6551s\n",
      "INFO:root:Epoch = [  3/ 15] Iter = [   0/2172] Loss = 0.2966 Avg Loss = 0.2966 Time = 8.2377s\n",
      "INFO:root:Epoch = [  3/ 15] Iter = [ 100/2172] Loss = 0.2717 Avg Loss = 0.3138 Time = 0.2756s\n",
      "INFO:root:Epoch = [  3/ 15] Iter = [ 200/2172] Loss = 0.3728 Avg Loss = 0.319 Time = 3.5781s\n",
      "INFO:root:Epoch = [  3/ 15] Iter = [ 300/2172] Loss = 0.3093 Avg Loss = 0.329 Time = 0.4636s\n",
      "INFO:root:Epoch = [  3/ 15] Iter = [ 400/2172] Loss = 0.2725 Avg Loss = 0.3242 Time = 3.6067s\n",
      "INFO:root:Epoch = [  3/ 15] Iter = [ 500/2172] Loss = 0.39 Avg Loss = 0.3217 Time = 1.3985s\n",
      "INFO:root:Epoch = [  3/ 15] Iter = [ 600/2172] Loss = 0.2785 Avg Loss = 0.3319 Time = 2.2041s\n",
      "INFO:root:Epoch = [  3/ 15] Iter = [ 700/2172] Loss = 0.4069 Avg Loss = 0.3218 Time = 0.2747s\n",
      "INFO:root:Epoch = [  3/ 15] Iter = [ 800/2172] Loss = 0.3216 Avg Loss = 0.3189 Time = 4.5166s\n",
      "INFO:root:Epoch = [  3/ 15] Iter = [ 900/2172] Loss = 0.3456 Avg Loss = 0.3204 Time = 0.2743s\n",
      "INFO:root:Epoch = [  3/ 15] Iter = [1000/2172] Loss = 0.2375 Avg Loss = 0.3179 Time = 5.1816s\n",
      "INFO:root:Epoch = [  3/ 15] Iter = [1100/2172] Loss = 0.3176 Avg Loss = 0.3088 Time = 0.2769s\n",
      "INFO:root:Epoch = [  3/ 15] Iter = [1200/2172] Loss = 0.2765 Avg Loss = 0.3131 Time = 3.8842s\n",
      "INFO:root:Epoch = [  3/ 15] Iter = [1300/2172] Loss = 0.3208 Avg Loss = 0.3179 Time = 0.2751s\n",
      "INFO:root:Epoch = [  3/ 15] Iter = [1400/2172] Loss = 0.3564 Avg Loss = 0.3209 Time = 3.8593s\n",
      "INFO:root:Epoch = [  3/ 15] Iter = [1500/2172] Loss = 0.3976 Avg Loss = 0.3277 Time = 1.4470s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  3/ 15] Iter = [1600/2172] Loss = 0.3294 Avg Loss = 0.3168 Time = 4.5278s\n",
      "INFO:root:Epoch = [  3/ 15] Iter = [1700/2172] Loss = 0.351 Avg Loss = 0.3149 Time = 0.2784s\n",
      "INFO:root:Epoch = [  3/ 15] Iter = [1800/2172] Loss = 0.2959 Avg Loss = 0.3155 Time = 4.5735s\n",
      "INFO:root:Epoch = [  3/ 15] Iter = [1900/2172] Loss = 0.3089 Avg Loss = 0.3147 Time = 0.2761s\n",
      "INFO:root:Epoch = [  3/ 15] Iter = [2000/2172] Loss = 0.26 Avg Loss = 0.3149 Time = 4.9215s\n",
      "INFO:root:Epoch = [  3/ 15] Iter = [2100/2172] Loss = 0.2428 Avg Loss = 0.3146 Time = 0.2769s\n",
      "INFO:root:Epoch = [   3/  15] TrainLoss = 0.3224 DevLoss = 0.0203 TrainTime = 1818.4685s DevTime = 164.3877s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [   0/2172] Loss = 0.3544 Avg Loss = 0.3544 Time = 7.4274s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [ 100/2172] Loss = 0.442 Avg Loss = 0.3326 Time = 0.2756s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [ 200/2172] Loss = 0.2338 Avg Loss = 0.3188 Time = 4.0543s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [ 300/2172] Loss = 0.3003 Avg Loss = 0.3222 Time = 0.2759s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [ 400/2172] Loss = 0.3203 Avg Loss = 0.3279 Time = 3.5912s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [ 500/2172] Loss = 0.3331 Avg Loss = 0.3167 Time = 0.2774s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [ 600/2172] Loss = 0.2983 Avg Loss = 0.3161 Time = 3.5181s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [ 700/2172] Loss = 0.2568 Avg Loss = 0.3149 Time = 0.2748s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [ 800/2172] Loss = 0.348 Avg Loss = 0.3177 Time = 0.3963s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [ 900/2172] Loss = 0.2819 Avg Loss = 0.3178 Time = 0.2740s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [1000/2172] Loss = 0.2772 Avg Loss = 0.3224 Time = 0.2743s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [1100/2172] Loss = 0.2479 Avg Loss = 0.3235 Time = 0.4272s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [1200/2172] Loss = 0.2754 Avg Loss = 0.3144 Time = 1.0357s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [1300/2172] Loss = 0.2169 Avg Loss = 0.3135 Time = 1.2969s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [1400/2172] Loss = 0.3772 Avg Loss = 0.3159 Time = 1.1656s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [1500/2172] Loss = 0.281 Avg Loss = 0.3195 Time = 3.7125s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [1600/2172] Loss = 0.2473 Avg Loss = 0.3173 Time = 2.2521s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [1700/2172] Loss = 0.2776 Avg Loss = 0.3122 Time = 0.2755s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [1800/2172] Loss = 0.4382 Avg Loss = 0.3158 Time = 0.8977s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [1900/2172] Loss = 0.3235 Avg Loss = 0.3166 Time = 0.2744s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [2000/2172] Loss = 0.3211 Avg Loss = 0.3166 Time = 0.2763s\n",
      "INFO:root:Epoch = [  4/ 15] Iter = [2100/2172] Loss = 0.2871 Avg Loss = 0.3171 Time = 2.5844s\n",
      "INFO:root:Epoch = [   4/  15] TrainLoss = 0.3153 DevLoss = 0.01936 TrainTime = 1821.2752s DevTime = 160.9340s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [   0/2172] Loss = 0.2697 Avg Loss = 0.2697 Time = 7.2130s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [ 100/2172] Loss = 0.4155 Avg Loss = 0.3043 Time = 0.2763s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [ 200/2172] Loss = 0.3086 Avg Loss = 0.3113 Time = 0.6823s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [ 300/2172] Loss = 0.2861 Avg Loss = 0.3215 Time = 0.2755s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [ 400/2172] Loss = 0.3172 Avg Loss = 0.3056 Time = 1.8417s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [ 500/2172] Loss = 0.362 Avg Loss = 0.3109 Time = 0.2736s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [ 600/2172] Loss = 0.3796 Avg Loss = 0.3177 Time = 0.2760s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [ 700/2172] Loss = 0.3434 Avg Loss = 0.3091 Time = 0.2788s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [ 800/2172] Loss = 0.4521 Avg Loss = 0.3149 Time = 0.2781s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [ 900/2172] Loss = 0.3192 Avg Loss = 0.3126 Time = 0.2750s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [1000/2172] Loss = 0.3508 Avg Loss = 0.3169 Time = 0.2766s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [1100/2172] Loss = 0.3656 Avg Loss = 0.3169 Time = 0.2741s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [1200/2172] Loss = 0.2456 Avg Loss = 0.3146 Time = 0.2756s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [1300/2172] Loss = 0.3144 Avg Loss = 0.3111 Time = 0.2750s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [1400/2172] Loss = 0.3978 Avg Loss = 0.3173 Time = 0.2752s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [1500/2172] Loss = 0.3285 Avg Loss = 0.3138 Time = 0.2740s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [1600/2172] Loss = 0.4158 Avg Loss = 0.314 Time = 0.2766s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [1700/2172] Loss = 0.3476 Avg Loss = 0.3108 Time = 0.2744s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [1800/2172] Loss = 0.3467 Avg Loss = 0.3177 Time = 0.2772s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [1900/2172] Loss = 0.4177 Avg Loss = 0.3173 Time = 0.2775s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [2000/2172] Loss = 0.3351 Avg Loss = 0.3205 Time = 0.2754s\n",
      "INFO:root:Epoch = [  5/ 15] Iter = [2100/2172] Loss = 0.2191 Avg Loss = 0.3152 Time = 0.2745s\n",
      "INFO:root:Epoch = [   5/  15] TrainLoss = 0.3209 DevLoss = 0.01961 TrainTime = 1823.8389s DevTime = 165.3953s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [   0/2172] Loss = 0.335 Avg Loss = 0.335 Time = 7.5037s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [ 100/2172] Loss = 0.3317 Avg Loss = 0.3247 Time = 0.2747s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [ 200/2172] Loss = 0.2829 Avg Loss = 0.312 Time = 3.6814s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [ 300/2172] Loss = 0.3612 Avg Loss = 0.3178 Time = 0.2744s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [ 400/2172] Loss = 0.229 Avg Loss = 0.313 Time = 1.1789s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [ 500/2172] Loss = 0.2883 Avg Loss = 0.3121 Time = 0.2763s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [ 600/2172] Loss = 0.3015 Avg Loss = 0.3165 Time = 3.3610s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [ 700/2172] Loss = 0.2318 Avg Loss = 0.3122 Time = 0.2782s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [ 800/2172] Loss = 0.2626 Avg Loss = 0.3128 Time = 1.4956s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [ 900/2172] Loss = 0.3028 Avg Loss = 0.3103 Time = 0.2751s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [1000/2172] Loss = 0.2424 Avg Loss = 0.317 Time = 2.3886s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [1100/2172] Loss = 0.3285 Avg Loss = 0.3148 Time = 0.2760s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [1200/2172] Loss = 0.2922 Avg Loss = 0.3185 Time = 2.6108s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [1300/2172] Loss = 0.2844 Avg Loss = 0.3094 Time = 0.2755s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [1400/2172] Loss = 0.2354 Avg Loss = 0.3121 Time = 1.3988s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [1500/2172] Loss = 0.2922 Avg Loss = 0.3134 Time = 0.2758s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [1600/2172] Loss = 0.276 Avg Loss = 0.313 Time = 0.2872s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [1700/2172] Loss = 0.4478 Avg Loss = 0.3128 Time = 0.2770s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [1800/2172] Loss = 0.2896 Avg Loss = 0.3199 Time = 1.8010s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [1900/2172] Loss = 0.2653 Avg Loss = 0.3089 Time = 0.2755s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [2000/2172] Loss = 0.3168 Avg Loss = 0.3184 Time = 1.9357s\n",
      "INFO:root:Epoch = [  6/ 15] Iter = [2100/2172] Loss = 0.2678 Avg Loss = 0.3159 Time = 0.2766s\n",
      "INFO:root:Epoch = [   6/  15] TrainLoss = 0.3142 DevLoss = 0.02028 TrainTime = 1821.0688s DevTime = 160.2641s\n",
      "INFO:root:Epoch = [  7/ 15] Iter = [   0/2172] Loss = 0.3041 Avg Loss = 0.3041 Time = 8.5625s\n",
      "INFO:root:Epoch = [  7/ 15] Iter = [ 100/2172] Loss = 0.3575 Avg Loss = 0.3132 Time = 0.2745s\n",
      "INFO:root:Epoch = [  7/ 15] Iter = [ 200/2172] Loss = 0.2564 Avg Loss = 0.3181 Time = 3.9152s\n",
      "INFO:root:Epoch = [  7/ 15] Iter = [ 300/2172] Loss = 0.3921 Avg Loss = 0.3135 Time = 0.2758s\n",
      "INFO:root:Epoch = [  7/ 15] Iter = [ 400/2172] Loss = 0.2982 Avg Loss = 0.3184 Time = 0.8899s\n",
      "INFO:root:Epoch = [  7/ 15] Iter = [ 500/2172] Loss = 0.2665 Avg Loss = 0.3164 Time = 0.2759s\n",
      "INFO:root:Epoch = [  7/ 15] Iter = [ 600/2172] Loss = 0.2755 Avg Loss = 0.3177 Time = 0.2769s\n",
      "INFO:root:Epoch = [  7/ 15] Iter = [ 700/2172] Loss = 0.3805 Avg Loss = 0.3153 Time = 0.2790s\n",
      "INFO:root:Epoch = [  7/ 15] Iter = [ 800/2172] Loss = 0.3126 Avg Loss = 0.3197 Time = 0.2756s\n",
      "INFO:root:Epoch = [  7/ 15] Iter = [ 900/2172] Loss = 0.3419 Avg Loss = 0.3232 Time = 0.2737s\n",
      "INFO:root:Epoch = [  7/ 15] Iter = [1000/2172] Loss = 0.3159 Avg Loss = 0.3211 Time = 0.2748s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  7/ 15] Iter = [1100/2172] Loss = 0.3165 Avg Loss = 0.3132 Time = 0.2736s\n",
      "INFO:root:Epoch = [  7/ 15] Iter = [1200/2172] Loss = 0.2641 Avg Loss = 0.314 Time = 0.2752s\n",
      "INFO:root:Epoch = [  7/ 15] Iter = [1300/2172] Loss = 0.2566 Avg Loss = 0.3108 Time = 0.2743s\n",
      "INFO:root:Epoch = [  7/ 15] Iter = [1400/2172] Loss = 0.3083 Avg Loss = 0.3109 Time = 0.2761s\n",
      "INFO:root:Epoch = [  7/ 15] Iter = [1500/2172] Loss = 0.3138 Avg Loss = 0.3148 Time = 0.2756s\n",
      "INFO:root:Epoch = [  7/ 15] Iter = [1600/2172] Loss = 0.2916 Avg Loss = 0.3052 Time = 0.2739s\n",
      "INFO:root:Epoch = [  7/ 15] Iter = [1700/2172] Loss = 0.2625 Avg Loss = 0.308 Time = 0.2739s\n",
      "INFO:root:Epoch = [  7/ 15] Iter = [1800/2172] Loss = 0.317 Avg Loss = 0.3061 Time = 0.8798s\n",
      "INFO:root:Epoch = [  7/ 15] Iter = [1900/2172] Loss = 0.2699 Avg Loss = 0.2994 Time = 0.2785s\n",
      "INFO:root:Epoch = [  7/ 15] Iter = [2000/2172] Loss = 0.2576 Avg Loss = 0.3075 Time = 1.5299s\n",
      "INFO:root:Epoch = [  7/ 15] Iter = [2100/2172] Loss = 0.3192 Avg Loss = 0.3154 Time = 0.2789s\n",
      "INFO:root:Epoch = [   7/  15] TrainLoss = 0.3075 DevLoss = 0.01917 TrainTime = 1820.1543s DevTime = 165.8005s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [   0/2172] Loss = 0.3136 Avg Loss = 0.3136 Time = 7.1781s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [ 100/2172] Loss = 0.2749 Avg Loss = 0.3121 Time = 0.2749s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [ 200/2172] Loss = 0.2713 Avg Loss = 0.313 Time = 4.9060s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [ 300/2172] Loss = 0.3205 Avg Loss = 0.3108 Time = 0.2752s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [ 400/2172] Loss = 0.3153 Avg Loss = 0.3168 Time = 4.8414s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [ 500/2172] Loss = 0.3196 Avg Loss = 0.3128 Time = 0.2752s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [ 600/2172] Loss = 0.2439 Avg Loss = 0.3121 Time = 4.5303s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [ 700/2172] Loss = 0.383 Avg Loss = 0.3072 Time = 0.2756s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [ 800/2172] Loss = 0.2672 Avg Loss = 0.3112 Time = 1.8916s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [ 900/2172] Loss = 0.2875 Avg Loss = 0.3058 Time = 0.2754s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [1000/2172] Loss = 0.312 Avg Loss = 0.3053 Time = 1.3909s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [1100/2172] Loss = 0.2932 Avg Loss = 0.308 Time = 0.2781s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [1200/2172] Loss = 0.2943 Avg Loss = 0.3083 Time = 0.7102s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [1300/2172] Loss = 0.2499 Avg Loss = 0.3083 Time = 0.2757s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [1400/2172] Loss = 0.2584 Avg Loss = 0.3085 Time = 0.5850s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [1500/2172] Loss = 0.3001 Avg Loss = 0.3007 Time = 0.2741s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [1600/2172] Loss = 0.2896 Avg Loss = 0.3183 Time = 1.9392s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [1700/2172] Loss = 0.3197 Avg Loss = 0.3177 Time = 0.2769s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [1800/2172] Loss = 0.2571 Avg Loss = 0.3102 Time = 4.6531s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [1900/2172] Loss = 0.3714 Avg Loss = 0.3179 Time = 0.2786s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [2000/2172] Loss = 0.2935 Avg Loss = 0.3182 Time = 3.0104s\n",
      "INFO:root:Epoch = [  8/ 15] Iter = [2100/2172] Loss = 0.2898 Avg Loss = 0.3151 Time = 0.2761s\n",
      "INFO:root:Epoch = [   8/  15] TrainLoss = 0.3085 DevLoss = 0.01907 TrainTime = 1818.2243s DevTime = 161.4811s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [   0/2172] Loss = 0.2886 Avg Loss = 0.2886 Time = 7.1735s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [ 100/2172] Loss = 0.2664 Avg Loss = 0.3031 Time = 0.2755s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [ 200/2172] Loss = 0.2964 Avg Loss = 0.3116 Time = 5.9327s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [ 300/2172] Loss = 0.3183 Avg Loss = 0.3152 Time = 0.2768s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [ 400/2172] Loss = 0.3149 Avg Loss = 0.3097 Time = 5.1767s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [ 500/2172] Loss = 0.2756 Avg Loss = 0.3108 Time = 0.2763s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [ 600/2172] Loss = 0.2032 Avg Loss = 0.3105 Time = 4.9410s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [ 700/2172] Loss = 0.264 Avg Loss = 0.3052 Time = 0.2762s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [ 800/2172] Loss = 0.2973 Avg Loss = 0.3097 Time = 4.2643s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [ 900/2172] Loss = 0.3026 Avg Loss = 0.3147 Time = 1.2079s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [1000/2172] Loss = 0.2898 Avg Loss = 0.3097 Time = 3.0698s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [1100/2172] Loss = 0.3469 Avg Loss = 0.3121 Time = 1.5688s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [1200/2172] Loss = 0.2404 Avg Loss = 0.3075 Time = 4.0676s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [1300/2172] Loss = 0.3192 Avg Loss = 0.3089 Time = 1.9641s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [1400/2172] Loss = 0.2383 Avg Loss = 0.3068 Time = 0.2745s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [1500/2172] Loss = 0.3995 Avg Loss = 0.3068 Time = 2.5281s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [1600/2172] Loss = 0.3097 Avg Loss = 0.314 Time = 0.5646s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [1700/2172] Loss = 0.2421 Avg Loss = 0.3061 Time = 1.6567s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [1800/2172] Loss = 0.3068 Avg Loss = 0.3092 Time = 3.5937s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [1900/2172] Loss = 0.4512 Avg Loss = 0.3177 Time = 0.2747s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [2000/2172] Loss = 0.26 Avg Loss = 0.3102 Time = 2.1501s\n",
      "INFO:root:Epoch = [  9/ 15] Iter = [2100/2172] Loss = 0.2595 Avg Loss = 0.3107 Time = 0.2782s\n",
      "INFO:root:Epoch = [   9/  15] TrainLoss = 0.3082 DevLoss = 0.01901 TrainTime = 1819.0404s DevTime = 164.0153s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [   0/2172] Loss = 0.346 Avg Loss = 0.346 Time = 7.4389s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [ 100/2172] Loss = 0.337 Avg Loss = 0.3256 Time = 0.2788s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [ 200/2172] Loss = 0.2698 Avg Loss = 0.3141 Time = 0.3366s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [ 300/2172] Loss = 0.356 Avg Loss = 0.308 Time = 0.7927s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [ 400/2172] Loss = 0.2805 Avg Loss = 0.3086 Time = 0.2750s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [ 500/2172] Loss = 0.2775 Avg Loss = 0.3101 Time = 0.2744s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [ 600/2172] Loss = 0.2479 Avg Loss = 0.3028 Time = 0.4583s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [ 700/2172] Loss = 0.444 Avg Loss = 0.3068 Time = 0.2768s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [ 800/2172] Loss = 0.4029 Avg Loss = 0.3112 Time = 0.2770s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [ 900/2172] Loss = 0.3107 Avg Loss = 0.3111 Time = 0.2773s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [1000/2172] Loss = 0.358 Avg Loss = 0.3145 Time = 0.2764s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [1100/2172] Loss = 0.2795 Avg Loss = 0.3084 Time = 0.2740s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [1200/2172] Loss = 0.3093 Avg Loss = 0.3076 Time = 0.2765s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [1300/2172] Loss = 0.4375 Avg Loss = 0.3123 Time = 0.2765s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [1400/2172] Loss = 0.2254 Avg Loss = 0.3111 Time = 0.2751s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [1500/2172] Loss = 0.2985 Avg Loss = 0.3058 Time = 0.2788s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [1600/2172] Loss = 0.2817 Avg Loss = 0.3033 Time = 0.2747s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [1700/2172] Loss = 0.2851 Avg Loss = 0.3068 Time = 0.2741s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [1800/2172] Loss = 0.3549 Avg Loss = 0.311 Time = 0.2766s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [1900/2172] Loss = 0.2739 Avg Loss = 0.3097 Time = 0.2737s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [2000/2172] Loss = 0.2748 Avg Loss = 0.3118 Time = 0.2757s\n",
      "INFO:root:Epoch = [ 10/ 15] Iter = [2100/2172] Loss = 0.2502 Avg Loss = 0.3124 Time = 0.2768s\n",
      "INFO:root:Epoch = [  10/  15] TrainLoss = 0.3091 DevLoss = 0.01922 TrainTime = 1817.7814s DevTime = 161.5963s\n",
      "INFO:root:Epoch = [ 11/ 15] Iter = [   0/2172] Loss = 0.3057 Avg Loss = 0.3057 Time = 7.6503s\n",
      "INFO:root:Epoch = [ 11/ 15] Iter = [ 100/2172] Loss = 0.2713 Avg Loss = 0.3079 Time = 0.2773s\n",
      "INFO:root:Epoch = [ 11/ 15] Iter = [ 200/2172] Loss = 0.3357 Avg Loss = 0.3108 Time = 2.4055s\n",
      "INFO:root:Epoch = [ 11/ 15] Iter = [ 300/2172] Loss = 0.3115 Avg Loss = 0.3056 Time = 1.4246s\n",
      "INFO:root:Epoch = [ 11/ 15] Iter = [ 400/2172] Loss = 0.3308 Avg Loss = 0.3105 Time = 3.8568s\n",
      "INFO:root:Epoch = [ 11/ 15] Iter = [ 500/2172] Loss = 0.4136 Avg Loss = 0.3125 Time = 0.2744s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 11/ 15] Iter = [ 600/2172] Loss = 0.2655 Avg Loss = 0.3092 Time = 3.2179s\n",
      "INFO:root:Epoch = [ 11/ 15] Iter = [ 700/2172] Loss = 0.5342 Avg Loss = 0.3132 Time = 0.2789s\n",
      "INFO:root:Epoch = [ 11/ 15] Iter = [ 800/2172] Loss = 0.3022 Avg Loss = 0.3138 Time = 4.9413s\n",
      "INFO:root:Epoch = [ 11/ 15] Iter = [ 900/2172] Loss = 0.2289 Avg Loss = 0.31 Time = 0.2756s\n",
      "INFO:root:Epoch = [ 11/ 15] Iter = [1000/2172] Loss = 0.2751 Avg Loss = 0.3105 Time = 4.6572s\n",
      "INFO:root:Epoch = [ 11/ 15] Iter = [1100/2172] Loss = 0.2308 Avg Loss = 0.3067 Time = 0.2778s\n",
      "INFO:root:Epoch = [ 11/ 15] Iter = [1200/2172] Loss = 0.3462 Avg Loss = 0.3084 Time = 5.1777s\n",
      "INFO:root:Epoch = [ 11/ 15] Iter = [1300/2172] Loss = 0.3089 Avg Loss = 0.3037 Time = 0.2778s\n",
      "INFO:root:Epoch = [ 11/ 15] Iter = [1400/2172] Loss = 0.2985 Avg Loss = 0.3044 Time = 4.7949s\n",
      "INFO:root:Epoch = [ 11/ 15] Iter = [1500/2172] Loss = 0.2446 Avg Loss = 0.304 Time = 0.2768s\n",
      "INFO:root:Epoch = [ 11/ 15] Iter = [1600/2172] Loss = 0.4377 Avg Loss = 0.3064 Time = 5.0005s\n",
      "INFO:root:Epoch = [ 11/ 15] Iter = [1700/2172] Loss = 0.2999 Avg Loss = 0.3091 Time = 0.2754s\n",
      "INFO:root:Epoch = [ 11/ 15] Iter = [1800/2172] Loss = 0.3603 Avg Loss = 0.311 Time = 2.8925s\n",
      "INFO:root:Epoch = [ 11/ 15] Iter = [1900/2172] Loss = 0.2815 Avg Loss = 0.3039 Time = 0.6706s\n",
      "INFO:root:Epoch = [ 11/ 15] Iter = [2000/2172] Loss = 0.3689 Avg Loss = 0.3081 Time = 0.2778s\n",
      "INFO:root:Epoch = [ 11/ 15] Iter = [2100/2172] Loss = 0.2847 Avg Loss = 0.3094 Time = 2.1140s\n",
      "INFO:root:Epoch = [  11/  15] TrainLoss = 0.3081 DevLoss = 0.01884 TrainTime = 1827.1491s DevTime = 164.9351s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [   0/2172] Loss = 0.2453 Avg Loss = 0.2453 Time = 7.9872s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [ 100/2172] Loss = 0.321 Avg Loss = 0.2896 Time = 0.2767s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [ 200/2172] Loss = 0.3168 Avg Loss = 0.2936 Time = 5.0264s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [ 300/2172] Loss = 0.3312 Avg Loss = 0.2998 Time = 0.2749s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [ 400/2172] Loss = 0.3496 Avg Loss = 0.3105 Time = 4.7121s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [ 500/2172] Loss = 0.2332 Avg Loss = 0.3111 Time = 0.2783s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [ 600/2172] Loss = 0.2157 Avg Loss = 0.3055 Time = 4.8762s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [ 700/2172] Loss = 0.3244 Avg Loss = 0.3112 Time = 0.2768s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [ 800/2172] Loss = 0.3243 Avg Loss = 0.3129 Time = 2.9649s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [ 900/2172] Loss = 0.4025 Avg Loss = 0.3135 Time = 0.2749s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [1000/2172] Loss = 0.2176 Avg Loss = 0.3014 Time = 2.8899s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [1100/2172] Loss = 0.2559 Avg Loss = 0.299 Time = 0.2763s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [1200/2172] Loss = 0.3416 Avg Loss = 0.3047 Time = 1.5353s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [1300/2172] Loss = 0.2573 Avg Loss = 0.3052 Time = 0.2752s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [1400/2172] Loss = 0.2628 Avg Loss = 0.3113 Time = 4.4030s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [1500/2172] Loss = 0.301 Avg Loss = 0.3118 Time = 0.2777s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [1600/2172] Loss = 0.2851 Avg Loss = 0.311 Time = 1.7788s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [1700/2172] Loss = 0.3768 Avg Loss = 0.3077 Time = 0.2737s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [1800/2172] Loss = 0.2398 Avg Loss = 0.3092 Time = 2.2090s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [1900/2172] Loss = 0.2479 Avg Loss = 0.3078 Time = 0.2759s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [2000/2172] Loss = 0.2409 Avg Loss = 0.3091 Time = 3.6101s\n",
      "INFO:root:Epoch = [ 12/ 15] Iter = [2100/2172] Loss = 0.4534 Avg Loss = 0.3118 Time = 0.2773s\n",
      "INFO:root:Epoch = [  12/  15] TrainLoss = 0.3126 DevLoss = 0.02028 TrainTime = 1827.2129s DevTime = 162.2850s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [   0/2172] Loss = 0.3597 Avg Loss = 0.3597 Time = 6.2045s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [ 100/2172] Loss = 0.2737 Avg Loss = 0.3301 Time = 0.2754s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [ 200/2172] Loss = 0.3484 Avg Loss = 0.3086 Time = 4.3197s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [ 300/2172] Loss = 0.2425 Avg Loss = 0.3056 Time = 0.2752s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [ 400/2172] Loss = 0.2257 Avg Loss = 0.3094 Time = 5.1207s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [ 500/2172] Loss = 0.3797 Avg Loss = 0.3038 Time = 0.2753s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [ 600/2172] Loss = 0.2893 Avg Loss = 0.3063 Time = 4.8109s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [ 700/2172] Loss = 0.2736 Avg Loss = 0.3065 Time = 1.6595s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [ 800/2172] Loss = 0.3946 Avg Loss = 0.3044 Time = 1.1999s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [ 900/2172] Loss = 0.3381 Avg Loss = 0.3079 Time = 0.2794s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [1000/2172] Loss = 0.3126 Avg Loss = 0.3118 Time = 0.4735s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [1100/2172] Loss = 0.2789 Avg Loss = 0.31 Time = 0.2746s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [1200/2172] Loss = 0.3997 Avg Loss = 0.3155 Time = 0.2764s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [1300/2172] Loss = 0.3761 Avg Loss = 0.3065 Time = 0.2779s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [1400/2172] Loss = 0.3803 Avg Loss = 0.3077 Time = 0.2741s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [1500/2172] Loss = 0.4139 Avg Loss = 0.3084 Time = 0.2759s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [1600/2172] Loss = 0.3229 Avg Loss = 0.3077 Time = 0.2753s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [1700/2172] Loss = 0.2861 Avg Loss = 0.3047 Time = 0.2772s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [1800/2172] Loss = 0.3731 Avg Loss = 0.3098 Time = 0.2774s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [1900/2172] Loss = 0.3306 Avg Loss = 0.3078 Time = 0.2751s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [2000/2172] Loss = 0.2797 Avg Loss = 0.3069 Time = 0.2741s\n",
      "INFO:root:Epoch = [ 13/ 15] Iter = [2100/2172] Loss = 0.4009 Avg Loss = 0.3049 Time = 0.2757s\n",
      "INFO:root:Epoch = [  13/  15] TrainLoss = 0.3111 DevLoss = 0.01878 TrainTime = 1823.3414s DevTime = 165.1632s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [   0/2172] Loss = 0.2756 Avg Loss = 0.2756 Time = 6.7088s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [ 100/2172] Loss = 0.3153 Avg Loss = 0.2945 Time = 2.4469s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [ 200/2172] Loss = 0.3532 Avg Loss = 0.3074 Time = 0.2862s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [ 300/2172] Loss = 0.3354 Avg Loss = 0.3111 Time = 5.9496s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [ 400/2172] Loss = 0.3176 Avg Loss = 0.3022 Time = 0.4142s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [ 500/2172] Loss = 0.2893 Avg Loss = 0.3025 Time = 4.1753s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [ 600/2172] Loss = 0.2758 Avg Loss = 0.3092 Time = 0.2753s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [ 700/2172] Loss = 0.4457 Avg Loss = 0.3116 Time = 3.9650s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [ 800/2172] Loss = 0.2276 Avg Loss = 0.3056 Time = 0.2760s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [ 900/2172] Loss = 0.3745 Avg Loss = 0.3095 Time = 3.6659s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [1000/2172] Loss = 0.2986 Avg Loss = 0.3183 Time = 0.2767s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [1100/2172] Loss = 0.4303 Avg Loss = 0.306 Time = 3.6615s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [1200/2172] Loss = 0.4034 Avg Loss = 0.3145 Time = 0.2745s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [1300/2172] Loss = 0.2737 Avg Loss = 0.306 Time = 5.1738s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [1400/2172] Loss = 0.3698 Avg Loss = 0.3019 Time = 0.2765s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [1500/2172] Loss = 0.2644 Avg Loss = 0.3031 Time = 3.8799s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [1600/2172] Loss = 0.2432 Avg Loss = 0.3082 Time = 0.2765s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [1700/2172] Loss = 0.4379 Avg Loss = 0.3043 Time = 4.1271s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [1800/2172] Loss = 0.2732 Avg Loss = 0.3039 Time = 0.2740s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [1900/2172] Loss = 0.2974 Avg Loss = 0.3115 Time = 3.7688s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [2000/2172] Loss = 0.3906 Avg Loss = 0.3029 Time = 0.2749s\n",
      "INFO:root:Epoch = [ 14/ 15] Iter = [2100/2172] Loss = 0.2795 Avg Loss = 0.3082 Time = 2.5153s\n",
      "INFO:root:Epoch = [  14/  15] TrainLoss = 0.3033 DevLoss = 0.01889 TrainTime = 1817.2567s DevTime = 162.6469s\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, args.num_epochs):\n",
    "    scheduler.step(epoch)\n",
    "    train_loss, train_time = train_epoch(args, epoch, model, train_loader, optimizer, writer)\n",
    "    dev_loss, dev_time = evaluate(args, epoch, model, dev_loader, writer)\n",
    "    visualize(args, epoch, model, display_loader, writer)\n",
    "\n",
    "    is_new_best = dev_loss < best_dev_loss\n",
    "    best_dev_loss = min(best_dev_loss, dev_loss)\n",
    "    save_model(args, args.exp_dir, epoch, model, optimizer, best_dev_loss, is_new_best)\n",
    "    logging.info(\n",
    "        f'Epoch = [{epoch:4d}/{args.num_epochs:4d}] TrainLoss = {train_loss:.4g} '\n",
    "        f'DevLoss = {dev_loss:.4g} TrainTime = {train_time:.4f}s DevTime = {dev_time:.4f}s',\n",
    "    )\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate validation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T02:42:07.052250Z",
     "start_time": "2019-09-09T02:42:07.047807Z"
    }
   },
   "outputs": [],
   "source": [
    "args.mask_kspace = True # ', action='store_true', help='Whether to apply a mask (set to True for val data and False for test data')\n",
    "args.data_split = 'val' # , choices=['val', 'test'], required=True, help='Which data partition to run on: \"val\" or \"test\"')\n",
    "args.checkpoint = pathlib.Path('input/checkpoints/best_model.pt') # ', type=pathlib.Path, required=True, help='Path to the U-Net model')\n",
    "args.out_dir = pathlib.Path('input/reconstruction_val/') # ', type=pathlib.Path, required=True, help='Path to save the reconstructions to')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T02:43:44.012106Z",
     "start_time": "2019-09-09T02:43:44.007725Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.unet.run_unet import run_unet, save_reconstructions, load_model, create_data_loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T02:44:38.793636Z",
     "start_time": "2019-09-09T02:43:48.096724Z"
    }
   },
   "outputs": [],
   "source": [
    "data_loader = create_data_loaders(args)\n",
    "model = load_model(args.checkpoint)\n",
    "reconstructions = run_unet(args, model, data_loader)\n",
    "save_reconstructions(reconstructions, args.out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T02:52:44.216723Z",
     "start_time": "2019-09-09T02:52:44.212241Z"
    }
   },
   "outputs": [],
   "source": [
    "from common.evaluate import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T02:55:32.001190Z",
     "start_time": "2019-09-09T02:54:49.779809Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chengjiun/Softwares/anaconda3/envs/py36_pytorch0.4/lib/python3.6/site-packages/skimage/util/arraycrop.py:177: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  cropped = ar[slices]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 1.488e-10 +/- 3.53e-10 NMSE = 0.04256 +/- 0.05487 PSNR = 30.67 +/- 5.924 SSIM = 0.6822 +/- 0.2848\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args.target_path = pathlib.Path('input/singlecoil_val/') # ', type=pathlib.Path, required=True, help='Path to the ground truth data')\n",
    "args.predictions_path = pathlib.Path('input/reconstruction_val/') # ', type=pathlib.Path, required=True, help='Path to reconstructions')\n",
    "args.acquisition = None# ', choices=['CORPD_FBK', 'CORPDFS_FBK'], default=None, help='If set, only volumes of the specified acquisition type are used for evaluation. By default, all volumes are included.')\n",
    "\n",
    "recons_key = 'reconstruction_rss' if args.challenge == 'multicoil' else 'reconstruction_esc'\n",
    "metrics = evaluate(args, recons_key)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T02:57:37.126345Z",
     "start_time": "2019-09-09T02:57:37.122050Z"
    }
   },
   "outputs": [],
   "source": [
    "args.mask_kspace = False # ', action='store_true', help='Whether to apply a mask (set to True for val data and False for test data')\n",
    "args.data_split = 'test_v2' # , choices=['val', 'test'], required=True, help='Which data partition to run on: \"val\" or \"test\"')\n",
    "args.checkpoint = pathlib.Path('input/checkpoints/best_model.pt') # ', type=pathlib.Path, required=True, help='Path to the U-Net model')\n",
    "args.out_dir = pathlib.Path('input/reconstruction_test/') # ', type=pathlib.Path, required=True, help='Path to save the reconstructions to')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T02:58:55.983629Z",
     "start_time": "2019-09-09T02:57:43.953791Z"
    }
   },
   "outputs": [],
   "source": [
    "data_loader = create_data_loaders(args)\n",
    "model = load_model(args.checkpoint)\n",
    "reconstructions = run_unet(args, model, data_loader)\n",
    "save_reconstructions(reconstructions, args.out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "real (pytorch 0.4)",
   "language": "python",
   "name": "pytorch0.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
